# TechLogistics S.A.S. - Sistema de Soporte a la DecisiÃ³n (DSS)

[![Streamlit App](https://img.shields.io/badge/Streamlit-App_en_Vivo-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)](https://validacion-casos-prueba-fwkqfjw5ebcbunkerzgq8o.streamlit.app)

> ğŸŒ **AplicaciÃ³n Web:** [https://validacion-casos-prueba-fwkqfjw5ebcbunkerzgq8o.streamlit.app](https://validacion-casos-prueba-fwkqfjw5ebcbunkerzgq8o.streamlit.app)

---

## ğŸ“‹ DescripciÃ³n del Proyecto

TechLogistics S.A.S. (Ficticio), un gigante del retail tecnolÃ³gico, ha detectado una erosiÃ³n en su margen de beneficios y una caÃ­da drÃ¡stica en la lealtad de sus clientes. La junta directiva sospecha que la causa raÃ­z es la invisibilidad operativa: sus tres sistemas principales (ERP de Inventarios, LogÃ­stica y Feedback) no hablan el mismo idioma. Este proyecto fue desarrollado como consultorÃ­a senior para realizar una curadurÃ­a profunda y diseÃ±ar un Sistema de Soporte a la DecisiÃ³n (DSS) en un Dashboard que transforme este caos en una estrategia de recuperaciÃ³n rentable.

---

## ğŸ¯ Objetivos

- AuditorÃ­a de calidad de datos
- IntegraciÃ³n de datasets heterogÃ©neos
- AnÃ¡lisis de rentabilidad y operaciones
- Recomendaciones estratÃ©gicas con IA

---

## ğŸ“ Estructura del Repositorio

```
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ feedback_clientes_v2.csv               
â”‚   â”œâ”€â”€ inventario_central_v2.csv           
â”‚   â””â”€â”€ transacciones_logistica_v2.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_cleaning.py        # MÃ³dulo de limpieza
â”‚   â”œâ”€â”€ feature_engineering.py  # CreaciÃ³n de variables
â”‚   â”œâ”€â”€ ai_integration.py       # IntegraciÃ³n con Groq
â”‚   â””â”€â”€ utils.py                # Funciones auxiliares
â”œâ”€â”€ streamlit_app.py            # Dashboard Streamlit
â”œâ”€â”€ requirements.txt            # Dependencias
â”œâ”€â”€ hallazgos.pdf              # Documento de hallazgos
â””â”€â”€ README.md
```

---

## ğŸš€ Ruta para la CreaciÃ³n del Proyecto

### Requisitos Previos
- Python 3.9+
- pip
- Cuenta Groq API (para IA)

### Pasos de InstalaciÃ³n

#### 1. Clonar repositorio
```bash
git clone https://github.com/Jvelasquez980/validacion-casos-prueba.git
```

#### 2. Crear entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

#### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

#### 4. Configurar variables de entorno
```bash
# Crear archivo .env con:
GROQ_API_KEY=tu_api_key_aqui
```

#### 5. Ejecutar Dashboard
```bash
streamlit run app.py
```

---

## ğŸ“Š Datasets Utilizados

1. **inventario_central_v2.csv** - Stock teÃ³rico reportado por el sistema ERP al inicio del trimestre
2. **transacciones_logistica_v2.csv** - Flujo de salida de mercancÃ­a y ejecuciÃ³n de la promesa de entrega
3. **feedback_clientes_v2.csv** - Datos cualitativos y cuantitativos de la experiencia post-venta

---

## ğŸ› ï¸ Desarrollo del Proyecto: Limpieza y AnÃ¡lisis de Datos

### Fase 1: Vista Inicial de los Datasets

Se empezÃ³ con una **vista inicial** de todos y cada uno de los datasets que se nos brindÃ³. Se realizÃ³ una exploraciÃ³n exhaustiva para comprender la estructura, tipos de datos y calidad de la informaciÃ³n disponible. AdemÃ¡s, se logrÃ³ obtener una **visiÃ³n clara de todos y cada uno de los aspectos negativos** de los datasets, identificando problemas de calidad, inconsistencias y valores faltantes.

---

### Fase 2: Limpieza Individual de Datasets

Se continuÃ³ el desarrollo con la **limpieza individual** de los datasets. Se crearon **3 distintos archivos .ipynb** en los cuales se ve cÃ³mo se planteÃ³ la limpieza de todos y cada uno de los datasets de forma individual.

#### Paso 1: EstandarizaciÃ³n de Datos

Primero se comenzÃ³ con la **estandarizaciÃ³n de los datos**. Muchas de las columnas que se encontraban tenÃ­an **datos mezclados**, lo cual hacÃ­a imposible que se realicen anÃ¡lisis de forma correcta. Se unificaron formatos de fecha, se corrigieron tipos de datos inconsistentes y se normalizaron escalas de mediciÃ³n.

#### Paso 2: Manejo de Outliers

Se continuÃ³ la limpieza con el **manejo de los outliers**. En algunos casos, debido a que fueron casos concretos, se realizaron **limpiezas concretas** a los datos extraÃ±os. Sin embargo, en otros datos se manejaron los outliers a partir de los **cuantiles identificados**, estableciendo lÃ­mites estadÃ­sticos para detectar y tratar valores atÃ­picos.

#### Paso 3: ImputaciÃ³n de Datos Nulos

Se continuÃ³ con la limpieza a partir de la **imputaciÃ³n de los datos nulos**. Se revisaban las columnas especÃ­ficas que contenÃ­an los datos nulos, y a partir de los tipos de datos se realizaron **distintas imputaciones**:

- Unas basadas Ãºnicamente en **medidas como la mediana**
- Otras que se fijaban en los **valores de las columnas adyacentes** para realizar las imputaciones

#### Paso 4: CorrecciÃ³n de Valores InvÃ¡lidos

Por Ãºltimo, en temas de limpieza, se corrigieron los **valores que eran invÃ¡lidos** (como negativos en precio de venta).

---

### Fase 3: Merge Unificado

Se creÃ³ el **merge unificado** que toma todos los valores de todos los datasets. Durante este proceso **se pierden 5,500 datos** que no contaban con las columnas suficientes para realizar el merge. Esta decisiÃ³n se toma **en pro de conservar datos orgÃ¡nicos** y mantener la integridad de la informaciÃ³n.

---

## ğŸ–¥ï¸ Desarrollo de la AplicaciÃ³n

DespuÃ©s de la limpieza, se realizÃ³ la aplicaciÃ³n siguiendo la siguiente estructura:

### Estructura de la AplicaciÃ³n

1. **Main (app.py)** - Archivo principal que inicia la aplicaciÃ³n

2. **PÃ¡ginas modulares** - Se continuÃ³ dividiendo la app en pÃ¡ginas que muestran la informaciÃ³n de los datasets

3. **GrÃ¡ficas personalizadas** - Cada una de estas vistas posee sus propias grÃ¡ficas

4. **Generador de informes** - Se implementa el generador de informes automatizado mediante Groq

---

## ğŸ”§ Funcionalidades del Dashboard

- **PestaÃ±a 1:** AuditorÃ­a de Calidad
- **PestaÃ±a 2:** AnÃ¡lisis Exploratorio
- **PestaÃ±a 3:** AnÃ¡lisis EstratÃ©gico
- **PestaÃ±a 4:** Recomendaciones IA

---

## ğŸ“ˆ MÃ©tricas Clave Calculadas

- Health Score por dataset
- Margen de Utilidad
- Brecha de Entrega vs Prometido
- Ratio de Soporte por CategorÃ­a

---

## ğŸ‘¥ Autores

- JerÃ³nimo VelÃ¡squez Escobar
- Manuela Caro Villada

---

## ğŸ“ Licencia

Proyecto acadÃ©mico - Universidad EAFIT 2026-1